---
title: "Covid Data Analysis"
subtitle: "Prediction Model of stock market and covid data"
author: "Covid_p11"
date: "2016/12/12 (updated: `r Sys.Date()`)"
output:
  xaringan::moon_reader:
    lib_dir: libs
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
---

```{r setup, include=FALSE}
# Data input and processing
options(htmltools.dir.version = FALSE)

library(tidyverse)
library(ggplot2)
library(maps)
library(plotly)
library(caret)
library(dplyr)
library(lubridate)
library(scales)
library(magrittr)
library(tidyr)
library(pkr)
library(plotly)
library(ggthemes)
library(tseries)
library(quantmod)
library(roll)
library(plotly)
library(gganimate)
library(tidyquant)
library(caret)
library(klaR)
library(zoo)
library(patchwork)

covid = read.csv("owid-covid-data.csv")
sp500 = read.csv("SPY Historical Data.csv", fileEncoding = 'UTF-8-BOM')
TOPIX = read.csv("TOPIX Historical Data.csv", fileEncoding = 'UTF-8-BOM')
ASX200 = read.csv("S&P_ASX 200 Historical Data.csv", fileEncoding = 'UTF-8-BOM')
NSEI = read.csv("Nifty 50 Historical Data.csv", fileEncoding = 'UTF-8-BOM') 
SSEC = read.csv("Shanghai Composite Historical Data.csv", fileEncoding = 'UTF-8-BOM') 
covid2 <- covid
covid2$date = as.character(ymd(covid2$date))
sp500$Date <- as.character(mdy(sp500$Date))
TOPIX$Date <- as.character(mdy(TOPIX$Date))
ASX200$Date <- as.character(mdy(ASX200$Date))
NSEI$Date <- as.character(mdy(NSEI$Date))
SSEC$Date <- as.character(mdy(SSEC$Date))

colnames(covid2)[4] = "Date"

covid_US <- covid2 %>% filter(location == "United States")
covid_AUS <- covid2 %>% filter(location == "Australia")
covid_IND <- covid2 %>% filter(location == "India")
covid_JPN <- covid2 %>% filter(location == "Japan")
covid_CHN <- covid2 %>% filter(location == "China")

df_1 = inner_join(sp500, covid_US, by = "Date")
df_2 = inner_join(TOPIX, covid_JPN, by = "Date")
df_3 = inner_join(ASX200, covid_AUS, by = "Date")
df_4 = inner_join(NSEI, covid_IND, by = "Date")
df_5 = inner_join(SSEC, covid_CHN, by = "Date")

covid_joined <- rbind(df_1, df_2, df_3, df_4, df_5)

covid_joined$Date <- ymd(covid_joined$Date)
covid_joined$Price <- as.numeric(gsub(",","",covid_joined$Price))
covid_joined$Open <- as.numeric(gsub(",","",covid_joined$Open))
covid_joined$High <- as.numeric(gsub(",","",covid_joined$High))
covid_joined$Low <- as.numeric(gsub(",","",covid_joined$Low))
covid_joined$Change.. <- as.numeric(gsub("%","",covid_joined$Change..))

covid_joined <- covid_joined %>% 
  filter(Date >= "2020-03-11") %>%
  mutate(Year_category = case_when( 
    Date >= "2020-03-11" & Date < "2021-01-01" ~ "1st year", 
    Date >= "2021-01-01" & Date < "2022-01-01" ~ "2nd year", 
    Date >= "2022-01-01" & Date < "2023-01-01" ~ "3rd year (ongoing)"))
```



class: inverse, middle, center

# Background & aim

---

## Analyse the relationship & impact of the Covid-19 on public equity markets and respective country economy.

--

  1.    Exploratory analysis of data

--
  
  2.    Correlation modelling & determining relationships

--
  
  3.    Model development and machine learning analysis

--

- Focusing on key countries (respective indices)

  - China

  - India

  - Japan

  - Australia

  - United States 

---

# Approach

- Data collection

  - Various methods of web scrapping and csv's joined with covid data
  
  - Using data from respective country index

--

- Data analysis

  - Adopting rolling window statistics

--

- Models

  - Adopting other models (PLS, RDA) to predict price levels 

---

class: inverse, middle, center

# Section 1: Exploratory Analysis

---

### Analysing distribution of gains and losses over pandemic for respective country stock market

--

- [Excess kurtosis](https://remarkjs.com) in 1st year is consistent with the covid crisis

- [Stablisation](https://remarkjs.com) over 2nd and 2rd year

```{r, include=FALSE}
covid_joined <- covid_joined %>% 
  filter(Date >= "2020-03-11") %>%
  mutate(Year_category = case_when( 
    Date >= "2020-03-11" & Date < "2021-01-01" ~ "1st year", 
    Date >= "2021-01-01" & Date < "2022-01-01" ~ "2nd year", 
    Date >= "2022-01-01" & Date < "2023-01-01" ~ "3rd year (ongoing)"))

fig <- plot_ly(covid_joined, x = ~Change.., y = ~location, color = ~Year_category, type = "box") %>% layout(boxmode = "group",
         xaxis = list(showgrid = TRUE),
         yaxis = list(showgrid = TRUE))

fig <- fig %>% layout(xaxis = list(title = 'daily gain/loss (%)'))
```


```{r, warning=FALSE, fig.height=5.5, fig.width=10, echo=FALSE}
fig
```

---

class: inverse, middle, center

# correlation modelling

---

# Correlation Matrix

```{r, include=FALSE}
df_q2 = covid_joined
colnames(df_q2)[7] = 'Change'
write.csv(df_q2,"df_q2.csv")

df_q2 = as.data.frame(df_q2[order(df_q2$Date),]) %>% drop_na(new_vaccinations, new_tests, new_cases, Price)
df_q2_cor = df_q2 %>% dplyr::select(new_vaccinations, new_tests, new_cases, Price)
```

```{r}
cor(df_q2_cor)
qtlcharts::iplotCorr(df_q2_cor)
```

---

```{r, include=FALSE}
df_q2_date = df_q2 %>% group_by(Date) %>% summarize(avg_price = mean(Price), avg_new_cases = mean(new_cases), avg_new_tests = mean(new_tests), avg_new_vac = mean(new_vaccinations))

nrow_df_q2 = 360
i = 1
cor1 <- list()
time_ls <- list()
j = 1
while (i <= nrow_df_q2) {
  subset <- df_q2_date[i:(i+29),]
  cor1[[j]] <- cor.test(subset$avg_price,subset$avg_new_vac, method = "pearson")
  time_ls[[j]] = subset$Date[1]
  print(time_ls[[j]])
  j = j + 1
  i = i + 30
}
out <- lapply(cor1, function(x) c(x$estimate, x$conf.int, x$p.value))
D1 <- data.frame(cbind(index = seq(length(out)), do.call(rbind, out)))
names(D1)[2:ncol(D1)] <- c('estimate', paste0('conf.int', 1:2), 'p.value')
#D1

i = 1
cor2 <- list()
j = 1
while (i <= nrow_df_q2) {
  subset <- df_q2_date[i:(i+29),]
  cor2[[j]] <- cor.test(subset$avg_new_tests,subset$avg_new_cases, method = "pearson")
  j = j + 1
  i = i + 30
}
out <- lapply(cor2, function(x) c(x$estimate, x$conf.int, x$p.value))
D2 <- data.frame(cbind(index = seq(length(out)), do.call(rbind, out)))
names(D2)[2:ncol(D2)] <- c('estimate', paste0('conf.int', 1:2), 'p.value')
df_q2_date = as.data.frame(time_ls)
df_q2_date = as.data.frame(t(df_q2_date))
#df_q2_date

colnames(D1)[1] ="start_date"
colnames(D1)[2] ="avg_price_avg_new_vacc"
colnames(D1)[3] ="avg_new_tests_avg_new_cases"
#,"avg_price_avg_new_vacc","avg_new_tests_avg_new_cases"
df_q2_cor_time = D1 %>% mutate(start_date = df_q2_date$V1, avg_new_tests_avg_new_cases = D2$estimate)
#cor_df_time
df_q2_cor_time$start_date = as.Date(df_q2_cor_time$start_date)
df_q2_cor_time = df_q2_cor_time[ , -which(names(df_q2_cor_time) %in% c("conf.int2","p.value"))]
#df_q2_cor_time
```

```{r, include=FALSE}
p1 = ggplot(data = df_q2_cor_time, aes(x = start_date)) + geom_line(aes(y=avg_new_tests_avg_new_cases, colour = "avg new_tests ~ avg new_cases"), size = 0.8) +
  geom_line(aes(y=avg_price_avg_new_vacc, colour = 'avg price ~ avg new_vacc'), size = 0.8) +
  scale_colour_manual("", 
                      values = c("avg new_tests ~ avg new_cases"="#FF00CC", "avg price ~ avg new_vacc"="#3333FF")) +
  ggtitle("Price~New_vaccinations, New_tests~New_cases") + xlab("Date") +
  ylab("Coorelation")+
  #scale_fill_manual(values = c("light green", "yellow"))+
  theme_bw()
```

# Correlation of variables over the time
```{r, fig.height=6, fig.width=10}
ggplotly(p1)
```

---

# Focused US (s&p500) analysis (150D rolling correlation)

--

- Vaccine manufacturers exhibited [anomalous](https://remarkjs.com) behavior 

- they reached [negative](https://remarkjs.com) correlation

- Pfizer significant [decreasing](https://remarkjs.com) correlation as pandemic progressed

```{r, include=FALSE}
mySymbols <- c('AMZN', '^GSPC','NFLX','MSFT','GOOG','NVAX','DIS','WMT','COST','V','FB','AXP','CMCSA','PFE','MRNA')
myStocks <-lapply(mySymbols, function(x) {getSymbols(x, src = "yahoo", 
                                                     from = "2020-01-01", 
                                                     to = "2022-04-04",
                                                     periodicity = "daily",
                                                     auto.assign=FALSE)} )

closePrices <- lapply(myStocks, Cl)
closePrices <- as.data.frame(do.call(merge, closePrices))
closePrices <- na.omit(log(closePrices/lag(closePrices)))
closePrices <- rownames_to_column(closePrices, "Date")

date <- closePrices["Date"]
date

# will need to probably write a function for this later as at the moment i am just hard coding this

corr_AMZN <- as.data.frame(roll_cor(closePrices$AMZN.Close, closePrices$GSPC.Close, width = 150)) %>% cbind(date) %>% na.omit
corr_NFLX <- as.data.frame(roll_cor(closePrices$NFLX.Close, closePrices$GSPC.Close, width = 150))%>% cbind(date) %>% na.omit
corr_MSFT <- as.data.frame(roll_cor(closePrices$MSFT.Close, closePrices$GSPC.Close, width = 150))%>% cbind(date) %>% na.omit
corr_GOOG <- as.data.frame(roll_cor(closePrices$GOOG.Close, closePrices$GSPC.Close, width = 150))%>% cbind(date) %>% na.omit
corr_NVAX <- as.data.frame(roll_cor(closePrices$NVAX.Close, closePrices$GSPC.Close, width = 150))%>% cbind(date) %>% na.omit
corr_DIS <- as.data.frame(roll_cor(closePrices$DIS.Close, closePrices$GSPC.Close, width = 150))%>% cbind(date) %>% na.omit
corr_WMT <- as.data.frame(roll_cor(closePrices$WMT.Close, closePrices$GSPC.Close, width = 150))%>% cbind(date) %>% na.omit
corr_COST <- as.data.frame(roll_cor(closePrices$COST.Close, closePrices$GSPC.Close, width = 150))%>% cbind(date) %>% na.omit
corr_V <- as.data.frame(roll_cor(closePrices$V.Close, closePrices$GSPC.Close, width = 150))%>% cbind(date) %>% na.omit
corr_FB <- as.data.frame(roll_cor(closePrices$FB.Close, closePrices$GSPC.Close, width = 150))%>% cbind(date) %>% na.omit
corr_AXP <- as.data.frame(roll_cor(closePrices$AXP.Close, closePrices$GSPC.Close, width = 150))%>% cbind(date) %>% na.omit
corr_CMCSA <- as.data.frame(roll_cor(closePrices$CMCSA.Close, closePrices$GSPC.Close, width = 150))%>% cbind(date) %>% na.omit
corr_PFE <- as.data.frame(roll_cor(closePrices$PFE.Close, closePrices$GSPC.Close, width = 150))%>% cbind(date) %>% na.omit
corr_MRNA <- as.data.frame(roll_cor(closePrices$MRNA.Close, closePrices$GSPC.Close, width = 150))%>% cbind(date) %>% na.omit

corr_AMZN$symbol <- "AMZN"
corr_NFLX$symbol <- "NFLX"
corr_GOOG$symbol <- "GOOG"
corr_NVAX$symbol <- "NVAX"
corr_V$symbol <- "VISA"
corr_FB$symbol <- "FB"
corr_MSFT$symbol <- "MSFT"
corr_PFE$symbol <- "PFE"
corr_MRNA$symbol <- "MRNA"

colnames(corr_AMZN)[1] = "corr"
colnames(corr_NFLX)[1] = "corr"
colnames(corr_MSFT)[1] = "corr"
colnames(corr_GOOG)[1] = "corr"
colnames(corr_NVAX)[1] = "corr"
colnames(corr_DIS)[1] = "corr"
colnames(corr_WMT)[1] = "corr"
colnames(corr_COST)[1] = "corr"
colnames(corr_V)[1] = "corr"
colnames(corr_FB)[1] = "corr"
colnames(corr_AXP)[1] = "corr"
colnames(corr_CMCSA)[1] = "corr"
colnames(corr_PFE)[1] = "corr"
colnames(corr_MRNA)[1] = "corr"

corr_joined = rbind(corr_AMZN, corr_NFLX, corr_GOOG, corr_NVAX, corr_V, corr_FB, corr_MSFT, corr_PFE, corr_MRNA)

corr_joined$Date <- as.Date(corr_joined$Date)
corr_joined

p = ggplot(corr_joined, aes(x=Date, y=corr, colour = symbol)) + geom_line() + labs(x = "Date", y = "rolling correlation (150D period)") + theme_bw()
```

```{r, fig.height=5.05, fig.width=9.1, echo=FALSE}
ggplotly(p)
```

class: inverse, middle, center

# model development and machine learning

---

class: center, middle

# Modeling

```{r, include=FALSE}
mean(df_q2_cor$Price)
median(df_q2_cor$Price)
quantile(df_q2_cor$Price, 0.25)

df_q2_cor <- df_q2_cor %>% mutate(level = case_when((df_q2_cor$Price <= 1978.28) ~ "Low",
                                                    ((df_q2_cor$Price > 1978.28) & (df_q2_cor$Price < 6511.446)) ~ "Medium",
                                         
                                                    (df_q2_cor$Price > 6511.446) ~ "High"
))

df_q2_cor$level <- as.factor(df_q2_cor$level)

# define training control
train_control <- trainControl(method="repeatedcv", number=10, repeats=3)
# train the model
model_knn <- train(level~., data=df_q2_cor, trControl=train_control, method="knn")
#model_rpart <- train(level~., data=df_q2_cor, trControl=train_control, method="rpart")
model_pls <- train(level~., data=df_q2_cor, trControl=train_control, method="pls")
model_rda <- train(level~., data=df_q2_cor, trControl=train_control, method="rda")
```

---

# Models developing and Machine learning

Using the historical data to classify and create models

--

- Classifying the Price data into 3 groups[(High, Median, Low)](https://remarkjs.com)

--

- building the model[(KNN,PLS,RDA)](https://remarkjs.com)

--

- calculate the accuracy of the model

--

- analysis and evaluate the model

--

- shiny app

--

- evaluation focused on accuracy comparison

--

---

# Analysis and accuracy evaluation

```{r model, fig.height=5.5, fig.width=10, echo=FALSE}
par(mfrow=c(3,1))
boxplot(model_knn$results$Accuracy, ylab = "knn",xlab = "Accuracy", horizontal = TRUE)
boxplot(model_pls$results$Accuracy, ylab = "pls",xlab = "Accuracy", horizontal = TRUE)
boxplot(model_rda$results$Accuracy, ylab = "rda",xlab = "Accuracy", horizontal = TRUE)
```

---

# group contribution

- Presentation: Maxim, Jasmine and Jia

- Q&A: all members

- Others:

- Section 1 code: Max

- Section 2 code: Jasmie and Christin

- Section 3 code: Paul and Marin

- Report: Jia

- Shiny app: Jinting

---